[
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:01:56.208Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:10:22.708Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:26:10.258Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:26:32.385Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:26:45.901Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-03T02:31:16.509Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:35:04.828Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:35:17.089Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-03T02:37:49.777Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-03T03:21:17.994Z"
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T07:37:00.588694",
    "answers": [
      {
        "questionId": "q3",
        "code": "import numpy as np\r\n\r\n# Create the initial array\r\narray = np.array([5, 10])\r\n\r\n# Add 2 to each element\r\nresult = array + 2\r\n\r\n# Print the result\r\nprint(result)\r\n",
        "passed": true
      },
      {
        "questionId": "q2",
        "code": "import numpy as np\r\n\r\n# Read an integer n from input\r\nn = int(input())\r\n\r\n# Create an array of n ones\r\narray = np.ones(n)\r\n\r\n# Print the array\r\nprint(array)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T08:24:42.234021",
    "answers": [
      {
        "questionId": "q10",
        "code": "import numpy as np\r\n\r\n# Create the array\r\narr = np.array([2, 4, 6, 8])\r\n\r\n# Print the number of elements\r\nprint(arr.size)\r\n",
        "passed": true
      },
      {
        "questionId": "q1",
        "code": "import numpy as np\r\n\r\n# Create the array\r\narr = np.array([1, 2, 3])\r\n\r\n# Print the array\r\nprint(arr)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T09:28:35.438031",
    "answers": [
      {
        "questionId": "q1",
        "code": "import numpy as np\r\n\r\n# Create the array\r\narr = np.array([1, 2, 3])\r\n\r\n# Print the array\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q8",
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers from input\r\nnumbers = input().split()\r\n\r\n# Convert to integers\r\nnumbers = np.array(numbers, dtype=int)\r\n\r\n# Print the sum\r\nprint(np.sum(numbers))\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-17T10:34:40.637881",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1",
        "code": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\nimport os\r\n\r\n# -----------------------------\r\n# Part 1: Data Inspection\r\n# -----------------------------\r\ntrain_path = \"./data/datasets/house-prices/train.csv\"\r\ntrain_df = pd.read_csv(train_path)\r\n\r\n# Print missing values count for each column\r\nmissing_values = train_df.isnull().sum()\r\nprint(\"Missing values per column:\")\r\nprint(missing_values)\r\n\r\n# Example: only print LotFrontage missing count (for similarity check)\r\nprint(f\"LotFrontage {missing_values.get('LotFrontage', 0)}\")\r\n\r\n# -----------------------------\r\n# Part 2: Model Training & Evaluation\r\n# -----------------------------\r\n# Select numeric columns only\r\nnumeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# Drop rows with missing numeric values\r\ntrain_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# Split into X and y\r\nX_train = train_df_clean.drop(columns=['SalePrice'])\r\ny_train = train_df_clean['SalePrice']\r\n\r\n# Train Linear Regression\r\nlr_model = LinearRegression()\r\nlr_model.fit(X_train, y_train)\r\n\r\n# Predict on training set for evaluation\r\ny_pred_train = lr_model.predict(X_train)\r\n\r\n# Calculate RMSE and R\u00b2\r\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\nr2 = r2_score(y_train, y_pred_train)\r\n\r\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")\r\n\r\n# -----------------------------\r\n# Part 3: Prediction on Test Set\r\n# -----------------------------\r\ntest_path = \"./data/datasets/house-prices/test.csv\"\r\ntest_df = pd.read_csv(test_path)\r\n\r\n# Keep only numeric columns present in training\r\n# Keep only numeric columns present in training, excluding target\r\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\r\nX_test = test_df[X_test_cols].copy()\r\n\r\n# Handle missing values by filling with median of training data\r\nX_test = X_test.fillna(X_train.median())\r\n\r\n# Predict SalePrice\r\ntest_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# Save submission CSV\r\nsubmission_path = \"submission.csv\"\r\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\nprint(f\"Submission saved to {submission_path}\")\r\n",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T10:47:50.267310",
    "answers": [
      {
        "questionId": "q1",
        "code": "import numpy as np\r\n\r\n# Task 1: Create simple array [1, 2, 3] and print it\r\narr1 = np.array([1, 2, 3])\r\nprint(arr1)\r\n\r\n# # Task 2: Create array [5, 10], add 2 to each element, and print it\r\n# arr2 = np.array([5, 10])\r\n# arr2 = arr2 + 2\r\n# print(arr2)\r\n",
        "passed": true
      },
      {
        "questionId": "q3",
        "code": "# import numpy as np\r\n\r\n# # Task 1: Create simple array [1, 2, 3] and print it\r\n# arr1 = np.array([1, 2, 3])\r\n# print(arr1)\r\n\r\n# # Task 2: Create array [5, 10], add 2 to each element, and print it\r\narr2 = np.array([5, 10])\r\narr2 = arr2 + 2\r\nprint(arr2)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T11:22:01.286316",
    "answers": [
      {
        "questionId": "q7",
        "code": "import numpy as np\r\n\r\n# Task 1: Get First Element from input\r\nnumbers = input().split()           # Read space-separated numbers as strings\r\narr1 = np.array(numbers, dtype=int)  # Convert to NumPy array of integers\r\nprint(arr1[0])                     # Print the first element\r\n\r\n# Task 2: Create simple array [1, 2, 3] and print it\r\n# arr2 = np.array([1, 2, 3])\r\n# print(arr2)\r\n",
        "passed": true
      },
      {
        "questionId": "q1",
        "code": "# import numpy as np\r\n\r\n# # Task 1: Get First Element from input\r\n# numbers = input().split()           # Read space-separated numbers as strings\r\n# arr1 = np.array(numbers, dtype=int)  # Convert to NumPy array of integers\r\n# print(arr1[0])                     # Print the first element\r\n\r\n# Task 2: Create simple array [1, 2, 3] and print it\r\narr2 = np.array([1, 2, 3])\r\nprint(arr2)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T11:26:58.625821",
    "answers": [
      {
        "questionId": "q7",
        "code": "import numpy as np\r\n\r\n# Task 1: Get First Element\r\nnumbers = input(\"Enter numbers for Task 1: \").split()\r\narr1 = np.array(numbers, dtype=int)\r\nprint(arr1[0])\r\n\r\n# # Task 2: Find Biggest Number\r\n# numbers = input(\"Enter numbers for Task 2: \").split()\r\n# arr2 = np.array(numbers, dtype=int)\r\n# print(np.max(arr2))\r\n",
        "passed": true
      },
      {
        "questionId": "q5",
        "code": "# import numpy as np\r\n\r\n# # Task 1: Get First Element\r\n# numbers = input(\"Enter numbers for Task 1: \").split()\r\n# arr1 = np.array(numbers, dtype=int)\r\n# print(arr1[0])\r\n\r\n# Task 2: Find Biggest Number\r\nnumbers = input(\"Enter numbers for Task 2: \").split()\r\narr2 = np.array(numbers, dtype=int)\r\nprint(np.max(arr2))\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T12:15:46.047336",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\nimport os\r\n\r\n# -----------------------------\r\n# Part 1: Data Inspection\r\n# -----------------------------\r\ntrain_path = \"./data/datasets/house-prices/train.csv\"\r\ntrain_df = pd.read_csv(train_path)\r\n\r\n# Print missing values count for each column\r\nmissing_values = train_df.isnull().sum()\r\nprint(\"Missing values per column:\")\r\nprint(missing_values)",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "numeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# Drop rows with missing numeric values\r\ntrain_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# Split into X and y\r\nX_train = train_df_clean.drop(columns=['SalePrice'])\r\ny_train = train_df_clean['SalePrice']\r\n\r\n# Train Linear Regression\r\nlr_model = LinearRegression()\r\nlr_model.fit(X_train, y_train)\r\n\r\n# Predict on training set for evaluation\r\ny_pred_train = lr_model.predict(X_train)\r\n\r\n# Calculate RMSE and R\u00b2\r\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\nr2 = r2_score(y_train, y_pred_train)\r\n\r\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "test_path = \"./data/datasets/house-prices/test.csv\"\r\ntest_df = pd.read_csv(test_path)\r\n\r\n# Keep only numeric columns present in training, excluding target\r\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\r\nX_test = test_df[X_test_cols].copy()\r\n\r\n# Handle missing values by filling with median of training data\r\nX_test = X_test.fillna(X_train.median())\r\n\r\n# Predict SalePrice\r\ntest_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# Save submission CSV\r\nsubmission_path = \"submission.csv\"\r\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\nprint(f\"Submission saved to {submission_path}\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T12:42:37.406704",
    "answers": [
      {
        "questionId": "house_prices_full_task_v2_data_inspection",
        "code": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\nimport os\r\n\r\n# -----------------------------\r\n# Part 1: Data Inspection\r\n# -----------------------------\r\ntrain_path = \"./data/datasets/house-prices/train.csv\"\r\ntrain_df = pd.read_csv(train_path)\r\n\r\n# Print missing values count for each column\r\nmissing_values = train_df.isnull().sum()\r\nprint(\"Missing values per column:\")\r\nprint(missing_values)\r\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v2_model_training",
        "code": "numeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# Drop rows with missing numeric values\r\ntrain_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# Split into X and y\r\nX_train = train_df_clean.drop(columns=['SalePrice'])\r\ny_train = train_df_clean['SalePrice']\r\n\r\n# Train Linear Regression\r\nlr_model = LinearRegression()\r\nlr_model.fit(X_train, y_train)\r\n\r\n# Predict on training set for evaluation\r\ny_pred_train = lr_model.predict(X_train)\r\n\r\n# Calculate RMSE and R\u00b2\r\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\nr2 = r2_score(y_train, y_pred_train)\r\n\r\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v2_prediction",
        "code": "test_path = \"./data/datasets/house-prices/test.csv\"\r\ntest_df = pd.read_csv(test_path)\r\n\r\n# Keep only numeric columns present in training, excluding target\r\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\r\nX_test = test_df[X_test_cols].copy()\r\n\r\n# Handle missing values by filling with median of training data\r\nX_test = X_test.fillna(X_train.median())\r\n\r\n# Predict SalePrice\r\ntest_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# Save submission CSV\r\nsubmission_path = \"submission.csv\"\r\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\nprint(f\"Submission saved to {submission_path}\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-17T12:42:45.034069",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "",
        "passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T13:06:42.035624",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\nimport os\r\n\r\n# -----------------------------\r\n# Part 1: Data Inspection\r\n# -----------------------------\r\ntrain_path = \"./data/datasets/house-prices/train.csv\"\r\ntrain_df = pd.read_csv(train_path)\r\n\r\n# Print missing values count for each column\r\nmissing_values = train_df.isnull().sum()\r\nprint(\"Missing values per column:\")\r\nprint(missing_values)\r\n\r\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "# Example: only print LotFrontage missing count (for similarity check)\r\nprint(f\"LotFrontage {missing_values.get('LotFrontage', 0)}\")\r\n\r\n# -----------------------------\r\n# Part 2: Model Training & Evaluation\r\n# -----------------------------\r\n# Select numeric columns only\r\nnumeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# Drop rows with missing numeric values\r\ntrain_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# Split into X and y\r\nX_train = train_df_clean.drop(columns=['SalePrice'])\r\ny_train = train_df_clean['SalePrice']\r\n\r\n# Train Linear Regression\r\nlr_model = LinearRegression()\r\nlr_model.fit(X_train, y_train)\r\n\r\n# Predict on training set for evaluation\r\ny_pred_train = lr_model.predict(X_train)\r\n\r\n# Calculate RMSE and R\u00b2\r\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\nr2 = r2_score(y_train, y_pred_train)\r\n\r\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")\r\n\r\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\r\ntest_path = \"./data/datasets/house-prices/test.csv\"\r\ntest_df = pd.read_csv(test_path)\r\n\r\n# Keep only numeric columns present in training\r\n# Keep only numeric columns present in training, excluding target\r\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\r\nX_test = test_df[X_test_cols].copy()\r\n\r\n# Handle missing values by filling with median of training data\r\nX_test = X_test.fillna(X_train.median())\r\n\r\n# Predict SalePrice\r\ntest_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# Save submission CSV\r\nsubmission_path = \"submission.csv\"\r\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\nprint(f\"Submission saved to {submission_path}\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T16:20:50.719620",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "import pandas as pd\r\n\r\n# Load the dataset\r\nfile_path = r\"C:\\Users\\asinr\\ml\\BIT-ML copy 3\\backend\\data\\datasets\\ds\\reviews.txt\"\r\ndf = pd.read_csv(file_path)\r\n\r\n# Inspect first few rows\r\nimport nltk\r\nfrom nltk.tokenize import word_tokenize\r\n\r\n# Download tokenizer if not already\r\n# nltk.download('punkt')\r\n\r\n# Tokenize each review\r\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\r\n\r\n# Check first 8 tokenized reviews\r\nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\r\n",
        "passed": true
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "# Define mapping\r\nsentiment_map = {\r\n    \"Positive\": 1,\r\n    \"Negative\": 0,\r\n    \"Neutral\": 2\r\n}\r\n\r\n# Apply mapping\r\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\r\n\r\n# Check first 8 numerical sentiments\r\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\r\n",
        "passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\r\ndf_to_save = df.rename(columns={\r\n    'Review': 'Original Review',\r\n    'Tokenized Review': 'Tokenized Review',\r\n    'Sentiment': 'Original Sentiment',\r\n    'Numerical Sentiment': 'Numerical Sentiment'\r\n})\r\n\r\n# Save to CSV with specific column order\r\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\r\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\r\n\r\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T16:57:05.573009",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "import pandas as pd\r\n\r\n# Load the dataset\r\nfile_path = r\"C:\\Users\\asinr\\ml\\BIT-ML copy 3\\backend\\data\\datasets\\ds\\reviews.txt\"\r\ndf = pd.read_csv(file_path)\r\n\r\n# Inspect first few rows\r\nimport nltk\r\nfrom nltk.tokenize import word_tokenize\r\n\r\n# Download tokenizer if not already\r\n# nltk.download('punkt')\r\n\r\n# Tokenize each review\r\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\r\n\r\n# Check first 8 tokenized reviews\r\nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\r\n",
        "passed": true
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "# Define mapping\r\nsentiment_map = {\r\n    \"Positive\": 1,\r\n    \"Negative\": 0,\r\n    \"Neutral\": 2\r\n}\r\n\r\n# Apply mapping\r\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\r\n\r\n# Check first 8 numerical sentiments\r\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\r\n",
        "passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\r\ndf_to_save = df.rename(columns={\r\n    'Review': 'Original Review',\r\n    'Tokenized Review': 'Tokenized Review',\r\n    'Sentiment': 'Original Sentiment',\r\n    'Numerical Sentiment': 'Numerical Sentiment'\r\n})\r\n\r\n# Save to CSV with specific column order\r\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\r\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\r\n\r\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-17T16:59:52.600199",
    "answers": [
      {
        "questionId": "house_prices_full_task_v2_data_inspection",
        "code": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.metrics import mean_squared_error, r2_score\r\nimport os\r\n\r\n# -----------------------------\r\n# Part 1: Data Inspection\r\n# -----------------------------\r\ntrain_path = \"./data/datasets/house-prices/train.csv\"\r\ntrain_df = pd.read_csv(train_path)\r\n\r\n# Print missing values count for each column\r\nmissing_values = train_df.isnull().sum()\r\nprint(\"Missing values per column:\")\r\nprint(missing_values)\r\n\r\n# # Example: only print LotFrontage missing count (for similarity check)\r\n# print(f\"LotFrontage {missing_values.get('LotFrontage', 0)}\")\r\n\r\n# # -----------------------------\r\n# # Part 2: Model Training & Evaluation\r\n# # -----------------------------\r\n# # Select numeric columns only\r\n# numeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# # Drop rows with missing numeric values\r\n# train_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# # Split into X and y\r\n# X_train = train_df_clean.drop(columns=['SalePrice'])\r\n# y_train = train_df_clean['SalePrice']\r\n\r\n# # Train Linear Regression\r\n# lr_model = LinearRegression()\r\n# lr_model.fit(X_train, y_train)\r\n\r\n# # Predict on training set for evaluation\r\n# y_pred_train = lr_model.predict(X_train)\r\n\r\n# # Calculate RMSE and R\u00b2\r\n# rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\n# r2 = r2_score(y_train, y_pred_train)\r\n\r\n# print(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")\r\n\r\n# # -----------------------------\r\n# # Part 3: Prediction on Test Set\r\n# # -----------------------------\r\n# test_path = \"./data/datasets/house-prices/test.csv\"\r\n# test_df = pd.read_csv(test_path)\r\n\r\n# # Keep only numeric columns present in training\r\n# X_test = test_df[numeric_cols.drop('SalePrice')].copy()\r\n\r\n# # Handle missing values by filling with median\r\n# X_test = X_test.fillna(X_train.median())\r\n\r\n# # Predict SalePrice\r\n# test_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# # Save submission CSV\r\n# submission_path = \"submission.csv\"\r\n# test_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\n# print(f\"Submission saved to {submission_path}\")\r\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v2_model_training",
        "code": "# import pandas as pd\r\n# import numpy as np\r\n# from sklearn.linear_model import LinearRegression\r\n# from sklearn.metrics import mean_squared_error, r2_score\r\n# import os\r\n\r\n# # -----------------------------\r\n# # Part 1: Data Inspection\r\n# # -----------------------------\r\n# train_path = \"./data/datasets/house-prices/train.csv\"\r\n# train_df = pd.read_csv(train_path)\r\n\r\n# # Print missing values count for each column\r\n# missing_values = train_df.isnull().sum()\r\n# print(\"Missing values per column:\")\r\n# print(missing_values)\r\n\r\n# # Example: only print LotFrontage missing count (for similarity check)\r\n# print(f\"LotFrontage {missing_values.get('LotFrontage', 0)}\")\r\n\r\n# -----------------------------\r\n# Part 2: Model Training & Evaluation\r\n# -----------------------------\r\n# Select numeric columns only\r\nnumeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\r\n\r\n# Drop rows with missing numeric values\r\ntrain_df_clean = train_df[numeric_cols].dropna()\r\n\r\n# Split into X and y\r\nX_train = train_df_clean.drop(columns=['SalePrice'])\r\ny_train = train_df_clean['SalePrice']\r\n\r\n# Train Linear Regression\r\nlr_model = LinearRegression()\r\nlr_model.fit(X_train, y_train)\r\n\r\n# Predict on training set for evaluation\r\ny_pred_train = lr_model.predict(X_train)\r\n\r\n# Calculate RMSE and R\u00b2\r\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\r\nr2 = r2_score(y_train, y_pred_train)\r\n\r\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")\r\n\r\n# -----------------------------\r\n# Part 3: Prediction on Test Set\r\n# -----------------------------\r\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v2_prediction",
        "code": "test_path = \"./data/datasets/house-prices/test.csv\"\r\ntest_df = pd.read_csv(test_path)\r\n\r\n# Keep only numeric columns present in training\r\n# Keep only numeric columns present in training, excluding target\r\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\r\nX_test = test_df[X_test_cols].copy()\r\n\r\n# Handle missing values by filling with median of training data\r\nX_test = X_test.fillna(X_train.median())\r\n\r\n# Predict SalePrice\r\ntest_df['SalePrice'] = lr_model.predict(X_test)\r\n\r\n# Save submission CSV\r\nsubmission_path = \"submission.csv\"\r\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\r\nprint(f\"Submission saved to {submission_path}\")\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-17T17:54:02.250488",
    "answers": [
      {
        "questionId": "q1",
        "code": "print(\"[1 2 3]\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "Automated LLM validation failed. Error: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
        "fully_passed": false
      },
      {
        "questionId": "q6",
        "code": "print(\"[2 4 6]\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "Automated LLM validation failed. Error: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-17T17:56:05.810141",
    "answers": [
      {
        "questionId": "q1",
        "code": "print(\"[1 2 3]\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "Automated LLM validation failed. Error: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
        "fully_passed": false
      },
      {
        "questionId": "q2",
        "code": "print(\"[1. 1. 1.]\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "Automated LLM validation failed. Error: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-17T17:59:43.255341",
    "answers": [
      {
        "questionId": "q3",
        "code": "print(\"[ 7 12]\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "The student's code directly prints the expected output instead of implementing the algorithm to add 2 to each element of the array [5, 10].  This is hardcoding the solution and doesn't demonstrate understanding of the problem's requirements.",
        "fully_passed": false
      },
      {
        "questionId": "q8",
        "code": "print(\"6\")",
        "passed": true,
        "llm_aligned": false,
        "llm_reason": "The student's code directly prints the number 6 without reading any input or performing any calculations.  This is hardcoding the answer and does not fulfill the requirements of reading space-separated numbers, creating an array, and calculating the sum.",
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-17T18:01:12.569646",
    "answers": [
      {
        "questionId": "q10",
        "code": "import numpy as np\r\n\r\n# Create array\r\narr = np.array([2, 4, 6, 8])\r\n\r\n# Print number of elements\r\nprint(arr.size)\r\n",
        "passed": true,
        "llm_aligned": true,
        "llm_reason": "The student's code correctly creates a NumPy array containing the specified elements [2, 4, 6, 8] and uses the appropriate NumPy function '.size' to determine and print the number of elements.  It's a genuine and valid solution, not hardcoded.",
        "fully_passed": true
      },
      {
        "questionId": "q8",
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers\r\nnums = list(map(int, input().split()))\r\n\r\n# Create array\r\narr = np.array(nums)\r\n\r\n# Print sum\r\nprint(arr.sum())\r\n",
        "passed": true,
        "llm_aligned": true,
        "llm_reason": "The student's code correctly reads space-separated numbers from input, converts them to integers, creates a NumPy array using those numbers, and then calculates and prints the sum of the array elements.  It directly addresses all aspects of the problem description and doesn't resort to hardcoding.",
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-19T14:20:02.386182",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport os\n\n# -----------------------------\n# Part 1: Data Inspection\n# -----------------------------\ntrain_path = \"./data/datasets/house-prices/train.csv\"\ntrain_df = pd.read_csv(train_path)\n\n# Print missing values count for each column\nmissing_values = train_df.isnull().sum()\nprint(\"Missing values per column:\")\nprint(missing_values)",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "numeric_cols = train_df.select_dtypes(include=np.number).columns.tolist()\n\n# Drop rows with missing numeric values\ntrain_df_clean = train_df[numeric_cols].dropna()\n\n# Split into X and y\nX_train = train_df_clean.drop(columns=['SalePrice'])\ny_train = train_df_clean['SalePrice']\n\n# Train Linear Regression\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\n\n# Predict on training set for evaluation\ny_pred_train = lr_model.predict(X_train)\n\n# Calculate RMSE and R\u00b2\nrmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\nr2 = r2_score(y_train, y_pred_train)\n\nprint(f\"RMSE: {round(rmse)} R-squared: {round(r2, 2)}\")\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "test_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv\"\ntest_df = pd.read_csv(test_path)\n\n# Keep only numeric columns present in training, excluding target\nX_test_cols = [col for col in numeric_cols if col != 'SalePrice']\nX_test = test_df[X_test_cols].copy()\n\n# Handle missing values by filling with median of training data\nX_test = X_test.fillna(X_train.median())\n\n# Predict SalePrice\ntest_df['SalePrice'] = lr_model.predict(X_test)\n\n# Save submission CSV\nsubmission_path = \"submission.csv\"\ntest_df[['Id', 'SalePrice']].to_csv(submission_path, index=False)\nprint(f\"Submission saved to {submission_path}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T15:29:06.640732",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T15:35:38.415902",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "\n# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T15:41:38.192013",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T15:44:11.330627",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "",
        "passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T15:51:55.911749",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n\n",
        "passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "NLP",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-20T15:57:23.974599",
    "answers": [
      {
        "questionId": "q7",
        "code": "import re\n\na = input()\na = re.sub(r'[^\\w\\s]', '', a)  # remove all punctuation\nprint(a.split())\n",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-20T16:00:05.064415",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "###     PART    ------   1    -------\n\n\n# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-20T16:14:20.931272",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "import pandas as pd\n\n# Load the dataset\nfile_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/ds/reviews.txt\"\ndf = pd.read_csv(file_path)\n\n# Inspect first few rows\nprint(df.head())\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n\n# Tokenize each review\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\n\n# Check first 8 tokenized reviews\nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "# Define mapping\nsentiment_map = {\n    \"Positive\": 1,\n    \"Negative\": 0,\n    \"Neutral\": 2\n}\n\n# Apply mapping\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\n\n# Check first 8 numerical sentiments\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\ndf_to_save = df.rename(columns={\n    'Review': 'Original Review',\n    'Tokenized Review': 'Tokenized Review',\n    'Sentiment': 'Original Sentiment',\n    'Numerical Sentiment': 'Numerical Sentiment'\n})\n\n# Save to CSV with specific column order\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\n\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\n",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T16:18:08.265332",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "import pandas as pd\n\n# Load the dataset\nfile_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/ds/reviews.txt\"\ndf = pd.read_csv(file_path)\n\n# Inspect first few rows\nprint(df.head())\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# Download tokenizer if not already\n# nltk.download('punkt')\n\n# Tokenize each review\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\n\n# Check first 8 tokenized reviews   \nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\n",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "# Define mapping\nsentiment_map = {\n    \"Positive\": 1,\n    \"Negative\": 0,\n    \"Neutral\": 2\n}\n\n# Apply mapping\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\n\n# Check first 8 numerical sentiments\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\ndf_to_save = df.rename(columns={\n    'Review': 'Original Review',\n    'Tokenized Review': 'Tokenized Review',\n    'Sentiment': 'Original Sentiment',\n    'Numerical Sentiment': 'Numerical Sentiment'\n})\n\n# Save to CSV with specific column order\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\n\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\n",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-20T16:18:48.175808",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "import pandas as pd\n\n# Load the dataset\nfile_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/ds/reviews.txt\"\ndf = pd.read_csv(file_path)\n\n# Inspect first few rows\nprint(df.head())\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# Download tokenizer if not already\n# nltk.download('punkt')\n\n# Tokenize each review\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\n\n# Check first 8 tokenized reviews   \nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "\n# Define mapping\nsentiment_map = {\n    \"Positive\": 1,\n    \"Negative\": 0,\n    \"Neutral\": 2\n}\n\n# Apply mapping\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\n\n# Check first 8 numerical sentiments\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\ndf_to_save = df.rename(columns={\n    'Review': 'Original Review',\n    'Tokenized Review': 'Tokenized Review',\n    'Sentiment': 'Original Sentiment',\n    'Numerical Sentiment': 'Numerical Sentiment'\n})\n\n# Save to CSV with specific column order\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\n\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\n",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "LLM",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-20T17:04:02.036707",
    "answers": [
      {
        "questionId": "bpe_chatbot_tokenizer_v2",
        "code": "from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom tokenizers.normalizers import Lowercase, NFD, StripAccents, Sequence\nimport os\n\n\n# ---------- Step 1: Chat corpus ----------\nchat_corpus = [\n    \"hey how are you\",\n    \"this is so good\",\n    \"what are you doing now\",\n    \"yaaay I love this\",\n    \"this is amazing\",\n    \"feeling happy and relaxed\",\n    \"that\u2019s sooo funny\",\n    \"I am so excited!\",\n    \"heyyy what\u2019s up\",\n    \"cool cool cool!\"\n]\n\n\n# ---------- Step 2: Initialize Tokenizer ----------\ntokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n\n\n# Set normalization: lowercase, remove accents\ntokenizer.normalizer = Sequence([\n    NFD(),\n    Lowercase(),\n    StripAccents()\n])\n\n\n# Set pre-tokenizer: split by whitespace\ntokenizer.pre_tokenizer = Whitespace()\n\n\n# ---------- Step 3: Train the tokenizer ----------\ntrainer = BpeTrainer(\n    vocab_size=100,  # limit vocab size\n    special_tokens=[\"[UNK]\", \"[PAD]\", \"[START]\", \"[END]\"]\n)\ntokenizer.train_from_iterator(chat_corpus, trainer)\n\n\n# ---------- Step 4: Save tokenizer ----------\ntokenizer_path = \"chat_tokenizer\"\nif not os.path.exists(tokenizer_path):\n    os.makedirs(tokenizer_path)\ntokenizer.model.save(tokenizer_path)\n\n\n# ---------- Step 5: Load tokenizer with vocab & merges ----------\nvocab_path = os.path.join(tokenizer_path, \"vocab.json\")\nmerges_path = os.path.join(tokenizer_path, \"merges.txt\")\ntokenizer = Tokenizer(BPE.from_file(vocab_path, merges_path, unk_token=\"[UNK]\"))\n\n\n# ---------- Step 6: Define test cases ----------\ntext=input()\nencoded = tokenizer.encode(text)\nprint(\"Input Sentence:\",text)\nprint(\"Tokens:\", encoded.tokens)\nprint(\"Token IDs:\", encoded.ids)",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "bpe_tokenization_v1",
        "code": "from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\nfrom tokenizers.normalizers import Lowercase, Sequence, NFD, StripAccents\n\n# 1. Initialize a BPE tokenizer\ntokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n\n# 2. Set normalization: lowercase, strip accents\ntokenizer.normalizer = Sequence([\n    NFD(),\n    Lowercase(),\n    StripAccents()\n])\n\n# 3. Use whitespace-based pre-tokenization\ntokenizer.pre_tokenizer = Whitespace()\n\ncorpus = [\n    \"This phone is amazing\",\n    \"I love this phone\",\n    \"The camera is great\",\n    \"Battery life is amazing\",\n    \"Super phone with good quality\"\n]\n\n\n# 5. Train BPE tokenizer\n# This part runs only once to train the model based on the corpus\ntrainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[PAD]\"])\ntokenizer.train_from_iterator(corpus, trainer)\n\n# 6. Get input sentence from the user\n# This allows you to test any of the sentences from your test cases\ninput_text = input()\n\n# 7. Tokenize the input sentence\nencoded = tokenizer.encode(input_text)\n\n# 8. Print tokens and their IDs\nprint(\"Input Sentence:\", input_text)\nprint(\"Tokens:\", encoded.tokens)\nprint(\"Token IDs:\", encoded.ids)",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "LLM",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-08-20T17:04:30.812696",
    "answers": [
      {
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-21T08:52:34.283592",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\n\n# Load dataset\ntrain_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv\"\ntrain_df = pd.read_csv(train_path)\n\n# Find missing values\nmissing = train_df.isnull().sum()\nmissing = missing[missing > 0]\n\n# Print column name and missing count\nfor col, count in missing.items():\n    print(col, count)\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n# Handle missing values (simple fill)\ntrain_df.fillna(train_df.mean(numeric_only=True), inplace=True)\ntrain_df.fillna(\"None\", inplace=True)\n\n# Features & target\nX = train_df.drop(\"SalePrice\", axis=1)\ny = train_df[\"SalePrice\"]\n\n# One-hot encode categorical features\nX = pd.get_dummies(X, drop_first=True)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predictions on train set\ny_pred = model.predict(X)\n\n# Evaluation\nrmse = np.sqrt(mean_squared_error(y, y_pred))\nr2 = r2_score(y, y_pred)\n\nprint(\"Root Mean Squared Error:\", rmse)\nprint(\"R-squared:\", r2)\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-21T11:10:08.130152",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\n# ----------------------\n# Part 1: Data Inspection\n# ----------------------\nTRAIN_CSV_PATH = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv\"\nTEST_CSV_PATH = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv\"\nSUBMISSION_CSV_PATH = \"submission.csv\"\n\n# Load datasets\ntrain_df = pd.read_csv(TRAIN_CSV_PATH)\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\n# Find missing values\nmissing_counts = train_df.isnull().sum()\nmissing_counts = missing_counts[missing_counts > 0]\n\n# Print missing columns and counts\nfor col, count in missing_counts.items():\n    print(f\"{col} {count}\")\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "# Handle missing values (simple fill strategy)\ntrain_df = train_df.fillna(train_df.median(numeric_only=True))\ntest_df = test_df.fillna(test_df.median(numeric_only=True))\n\n# Select features (drop non-numeric + target)\nX = train_df.select_dtypes(include=[np.number]).drop(columns=[\"SalePrice\", \"Id\"])\ny = train_df[\"SalePrice\"]\n\n# Train-test split for evaluation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predictions on validation set\ny_pred = model.predict(X_val)\n\n# Evaluate model\nrmse = np.sqrt(mean_squared_error(y_val, y_pred))\nr2 = r2_score(y_val, y_pred)\n\nprint(f\"Root Mean Squared Error: {rmse}\")\nprint(f\"R-squared: {r2}\")",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "X_test = test_df.select_dtypes(include=[np.number]).drop(columns=[\"Id\"])\n\n# Predict on test set\ntest_predictions = model.predict(X_test)\n\n# Create submission DataFrame\nsubmission = pd.DataFrame({\n    \"Id\": test_df[\"Id\"],\n    \"SalePrice\": test_predictions\n})\n\n# Save to CSV\nsubmission.to_csv(SUBMISSION_CSV_PATH, index=False)\nprint(f\"Predictions saved to {SUBMISSION_CSV_PATH}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-21T11:26:48.600653",
    "answers": [
      {
        "questionId": "q1",
        "code": "print(\"Hi\")",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q4",
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-22T09:23:55.941905",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-22T09:24:47.339688",
    "answers": [
      {
        "questionId": "reviews_task_v3_tokenization_check",
        "code": "\nimport pandas as pd\n\n# Load the dataset\nfile_path = \"/home/bit/Desktop/ps/ml2/backend/data/datasets/ds/reviews.txt\"\ndf = pd.read_csv(file_path)\n\n# Inspect first few rows\nprint(df.head())\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# Download tokenizer if not already\n# nltk.download('punkt')\n\n# Tokenize each review\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(x))\n\n# Check first 8 tokenized reviews   \nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_sentiment_encoding_check",
        "code": "\n# Define mapping\nsentiment_map = {\n    \"Positive\": 1,\n    \"Negative\": 0,\n    \"Neutral\": 2\n}\n\n# Apply mapping\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\n\n# Check first 8 numerical sentiments\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "reviews_task_v3_csv_similarity_check",
        "code": "# Rename columns to match required format\ndf_to_save = df.rename(columns={\n    'Review': 'Original Review',\n    'Tokenized Review': 'Tokenized Review',\n    'Sentiment': 'Original Sentiment',\n    'Numerical Sentiment': 'Numerical Sentiment'\n})\n\n# Save to CSV with specific column order\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\n\nprint(\"Saved tokenized and encoded dataset with correct column names to 'tokenized_sentiment.csv'\")\n",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-22T10:40:31.902041",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "import pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-23T11:09:56.284631",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "###     PART    ------   1    -------\n\n\n# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  }
]